# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ..commons.types.model import Model
from ..commons.types.model_usage_unit import ModelUsageUnit
from ..commons.types.pricing_tier_input import PricingTierInput
from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from .raw_client import AsyncRawModelsClient, RawModelsClient
from .types.paginated_models import PaginatedModels

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class ModelsClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawModelsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawModelsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawModelsClient
        """
        return self._raw_client

    def create(
        self,
        *,
        model_name: str,
        match_pattern: str,
        start_date: typing.Optional[dt.datetime] = OMIT,
        unit: typing.Optional[ModelUsageUnit] = OMIT,
        input_price: typing.Optional[float] = OMIT,
        output_price: typing.Optional[float] = OMIT,
        total_price: typing.Optional[float] = OMIT,
        pricing_tiers: typing.Optional[typing.Sequence[PricingTierInput]] = OMIT,
        tokenizer_id: typing.Optional[str] = OMIT,
        tokenizer_config: typing.Optional[typing.Any] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Model:
        """
        Create a model

        Parameters
        ----------
        model_name : str
            Name of the model definition. If multiple with the same name exist, they are applied in the following order: (1) custom over built-in, (2) newest according to startTime where model.startTime<observation.startTime

        match_pattern : str
            Regex pattern which matches this model definition to generation.model. Useful in case of fine-tuned models. If you want to exact match, use `(?i)^modelname$`

        start_date : typing.Optional[dt.datetime]
            Apply only to generations which are newer than this ISO date.

        unit : typing.Optional[ModelUsageUnit]
            Unit used by this model.

        input_price : typing.Optional[float]
            Deprecated. Use 'pricingTiers' instead. Price (USD) per input unit. Creates a default tier if pricingTiers not provided.

        output_price : typing.Optional[float]
            Deprecated. Use 'pricingTiers' instead. Price (USD) per output unit. Creates a default tier if pricingTiers not provided.

        total_price : typing.Optional[float]
            Deprecated. Use 'pricingTiers' instead. Price (USD) per total units. Cannot be set if input or output price is set. Creates a default tier if pricingTiers not provided.

        pricing_tiers : typing.Optional[typing.Sequence[PricingTierInput]]
            Optional. Array of pricing tiers for this model.

            Use pricing tiers for all models - both those with threshold-based pricing variations and those with simple flat pricing:

            - For models with standard flat pricing: Create a single default tier with your prices
              (e.g., one tier with isDefault=true, priority=0, conditions=[], and your standard prices)

            - For models with threshold-based pricing: Create a default tier plus additional conditional tiers
              (e.g., default tier for standard usage + high-volume tier for usage above certain thresholds)

            Requirements:
            - Cannot be provided with flat prices (inputPrice/outputPrice/totalPrice) - use one approach or the other
            - Must include exactly one default tier with isDefault=true, priority=0, and conditions=[]
            - All tier names and priorities must be unique within the model
            - Each tier must define at least one price

            If omitted, you must provide flat prices instead (inputPrice/outputPrice/totalPrice),
            which will automatically create a single default tier named "Standard".

        tokenizer_id : typing.Optional[str]
            Optional. Tokenizer to be applied to observations which match to this model. See docs for more details.

        tokenizer_config : typing.Optional[typing.Any]
            Optional. Configuration for the selected tokenizer. Needs to be JSON. See docs for more details.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Model

        Examples
        --------
        from langfuse import LangfuseAPI

        client = LangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )
        client.models.create(
            model_name="modelName",
            match_pattern="matchPattern",
        )
        """
        _response = self._raw_client.create(
            model_name=model_name,
            match_pattern=match_pattern,
            start_date=start_date,
            unit=unit,
            input_price=input_price,
            output_price=output_price,
            total_price=total_price,
            pricing_tiers=pricing_tiers,
            tokenizer_id=tokenizer_id,
            tokenizer_config=tokenizer_config,
            request_options=request_options,
        )
        return _response.data

    def list(
        self,
        *,
        page: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedModels:
        """
        Get all models

        Parameters
        ----------
        page : typing.Optional[int]
            page number, starts at 1

        limit : typing.Optional[int]
            limit of items per page

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedModels

        Examples
        --------
        from langfuse import LangfuseAPI

        client = LangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )
        client.models.list()
        """
        _response = self._raw_client.list(
            page=page, limit=limit, request_options=request_options
        )
        return _response.data

    def get(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> Model:
        """
        Get a model

        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Model

        Examples
        --------
        from langfuse import LangfuseAPI

        client = LangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )
        client.models.get(
            id="id",
        )
        """
        _response = self._raw_client.get(id, request_options=request_options)
        return _response.data

    def delete(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a model. Cannot delete models managed by Langfuse. You can create your own definition with the same modelName to override the definition though.

        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        from langfuse import LangfuseAPI

        client = LangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )
        client.models.delete(
            id="id",
        )
        """
        _response = self._raw_client.delete(id, request_options=request_options)
        return _response.data


class AsyncModelsClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawModelsClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawModelsClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawModelsClient
        """
        return self._raw_client

    async def create(
        self,
        *,
        model_name: str,
        match_pattern: str,
        start_date: typing.Optional[dt.datetime] = OMIT,
        unit: typing.Optional[ModelUsageUnit] = OMIT,
        input_price: typing.Optional[float] = OMIT,
        output_price: typing.Optional[float] = OMIT,
        total_price: typing.Optional[float] = OMIT,
        pricing_tiers: typing.Optional[typing.Sequence[PricingTierInput]] = OMIT,
        tokenizer_id: typing.Optional[str] = OMIT,
        tokenizer_config: typing.Optional[typing.Any] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> Model:
        """
        Create a model

        Parameters
        ----------
        model_name : str
            Name of the model definition. If multiple with the same name exist, they are applied in the following order: (1) custom over built-in, (2) newest according to startTime where model.startTime<observation.startTime

        match_pattern : str
            Regex pattern which matches this model definition to generation.model. Useful in case of fine-tuned models. If you want to exact match, use `(?i)^modelname$`

        start_date : typing.Optional[dt.datetime]
            Apply only to generations which are newer than this ISO date.

        unit : typing.Optional[ModelUsageUnit]
            Unit used by this model.

        input_price : typing.Optional[float]
            Deprecated. Use 'pricingTiers' instead. Price (USD) per input unit. Creates a default tier if pricingTiers not provided.

        output_price : typing.Optional[float]
            Deprecated. Use 'pricingTiers' instead. Price (USD) per output unit. Creates a default tier if pricingTiers not provided.

        total_price : typing.Optional[float]
            Deprecated. Use 'pricingTiers' instead. Price (USD) per total units. Cannot be set if input or output price is set. Creates a default tier if pricingTiers not provided.

        pricing_tiers : typing.Optional[typing.Sequence[PricingTierInput]]
            Optional. Array of pricing tiers for this model.

            Use pricing tiers for all models - both those with threshold-based pricing variations and those with simple flat pricing:

            - For models with standard flat pricing: Create a single default tier with your prices
              (e.g., one tier with isDefault=true, priority=0, conditions=[], and your standard prices)

            - For models with threshold-based pricing: Create a default tier plus additional conditional tiers
              (e.g., default tier for standard usage + high-volume tier for usage above certain thresholds)

            Requirements:
            - Cannot be provided with flat prices (inputPrice/outputPrice/totalPrice) - use one approach or the other
            - Must include exactly one default tier with isDefault=true, priority=0, and conditions=[]
            - All tier names and priorities must be unique within the model
            - Each tier must define at least one price

            If omitted, you must provide flat prices instead (inputPrice/outputPrice/totalPrice),
            which will automatically create a single default tier named "Standard".

        tokenizer_id : typing.Optional[str]
            Optional. Tokenizer to be applied to observations which match to this model. See docs for more details.

        tokenizer_config : typing.Optional[typing.Any]
            Optional. Configuration for the selected tokenizer. Needs to be JSON. See docs for more details.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Model

        Examples
        --------
        import asyncio

        from langfuse import AsyncLangfuseAPI

        client = AsyncLangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.models.create(
                model_name="modelName",
                match_pattern="matchPattern",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.create(
            model_name=model_name,
            match_pattern=match_pattern,
            start_date=start_date,
            unit=unit,
            input_price=input_price,
            output_price=output_price,
            total_price=total_price,
            pricing_tiers=pricing_tiers,
            tokenizer_id=tokenizer_id,
            tokenizer_config=tokenizer_config,
            request_options=request_options,
        )
        return _response.data

    async def list(
        self,
        *,
        page: typing.Optional[int] = None,
        limit: typing.Optional[int] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> PaginatedModels:
        """
        Get all models

        Parameters
        ----------
        page : typing.Optional[int]
            page number, starts at 1

        limit : typing.Optional[int]
            limit of items per page

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        PaginatedModels

        Examples
        --------
        import asyncio

        from langfuse import AsyncLangfuseAPI

        client = AsyncLangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.models.list()


        asyncio.run(main())
        """
        _response = await self._raw_client.list(
            page=page, limit=limit, request_options=request_options
        )
        return _response.data

    async def get(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> Model:
        """
        Get a model

        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        Model

        Examples
        --------
        import asyncio

        from langfuse import AsyncLangfuseAPI

        client = AsyncLangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.models.get(
                id="id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.get(id, request_options=request_options)
        return _response.data

    async def delete(
        self, id: str, *, request_options: typing.Optional[RequestOptions] = None
    ) -> None:
        """
        Delete a model. Cannot delete models managed by Langfuse. You can create your own definition with the same modelName to override the definition though.

        Parameters
        ----------
        id : str

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        None

        Examples
        --------
        import asyncio

        from langfuse import AsyncLangfuseAPI

        client = AsyncLangfuseAPI(
            x_langfuse_sdk_name="YOUR_X_LANGFUSE_SDK_NAME",
            x_langfuse_sdk_version="YOUR_X_LANGFUSE_SDK_VERSION",
            x_langfuse_public_key="YOUR_X_LANGFUSE_PUBLIC_KEY",
            username="YOUR_USERNAME",
            password="YOUR_PASSWORD",
            base_url="https://yourhost.com/path/to/api",
        )


        async def main() -> None:
            await client.models.delete(
                id="id",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.delete(id, request_options=request_options)
        return _response.data
